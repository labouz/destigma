{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "liwc = pd.read_csv(\"../data/data_analysis/LIWC-22 Results - directed_stigma - LIWC Analysis.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take the average across all vars\n",
    "liwc_vars = liwc.columns[23:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# averages\n",
    "liwc_avg = liwc[liwc_vars].mean()\n",
    "liwc_avg = liwc_avg.sort_values(ascending=False)\n",
    "# liwc_avg.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Dic</th>\n",
       "      <td>90.808558</td>\n",
       "      <td>62.50</td>\n",
       "      <td>100.00</td>\n",
       "      <td>5.239110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Linguistic</th>\n",
       "      <td>72.499836</td>\n",
       "      <td>27.27</td>\n",
       "      <td>91.04</td>\n",
       "      <td>6.997561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>function</th>\n",
       "      <td>57.432591</td>\n",
       "      <td>18.18</td>\n",
       "      <td>81.82</td>\n",
       "      <td>6.368442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Authentic</th>\n",
       "      <td>48.427896</td>\n",
       "      <td>1.00</td>\n",
       "      <td>99.00</td>\n",
       "      <td>31.763705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Clout</th>\n",
       "      <td>45.867363</td>\n",
       "      <td>1.00</td>\n",
       "      <td>99.00</td>\n",
       "      <td>32.822569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Analytic</th>\n",
       "      <td>28.277147</td>\n",
       "      <td>1.00</td>\n",
       "      <td>99.00</td>\n",
       "      <td>23.017036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WPS</th>\n",
       "      <td>21.514736</td>\n",
       "      <td>4.75</td>\n",
       "      <td>290.00</td>\n",
       "      <td>20.345839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tone</th>\n",
       "      <td>21.153525</td>\n",
       "      <td>1.00</td>\n",
       "      <td>99.00</td>\n",
       "      <td>23.996762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>verb</th>\n",
       "      <td>19.156095</td>\n",
       "      <td>0.00</td>\n",
       "      <td>36.84</td>\n",
       "      <td>4.194490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pronoun</th>\n",
       "      <td>18.356711</td>\n",
       "      <td>0.00</td>\n",
       "      <td>45.45</td>\n",
       "      <td>5.386416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AllPunc</th>\n",
       "      <td>18.321898</td>\n",
       "      <td>0.00</td>\n",
       "      <td>101.59</td>\n",
       "      <td>7.788403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Social</th>\n",
       "      <td>14.719523</td>\n",
       "      <td>0.00</td>\n",
       "      <td>42.22</td>\n",
       "      <td>5.811295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BigWords</th>\n",
       "      <td>14.115044</td>\n",
       "      <td>0.00</td>\n",
       "      <td>50.00</td>\n",
       "      <td>5.026009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ppron</th>\n",
       "      <td>13.671242</td>\n",
       "      <td>0.00</td>\n",
       "      <td>28.85</td>\n",
       "      <td>5.116679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cognition</th>\n",
       "      <td>13.460431</td>\n",
       "      <td>0.00</td>\n",
       "      <td>37.04</td>\n",
       "      <td>4.596143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>det</th>\n",
       "      <td>13.227912</td>\n",
       "      <td>0.00</td>\n",
       "      <td>36.36</td>\n",
       "      <td>3.493142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prep</th>\n",
       "      <td>12.263474</td>\n",
       "      <td>0.00</td>\n",
       "      <td>29.41</td>\n",
       "      <td>3.147768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cogproc</th>\n",
       "      <td>11.582760</td>\n",
       "      <td>0.00</td>\n",
       "      <td>29.23</td>\n",
       "      <td>4.305169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>socrefs</th>\n",
       "      <td>10.874130</td>\n",
       "      <td>0.00</td>\n",
       "      <td>33.33</td>\n",
       "      <td>5.016941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>auxverb</th>\n",
       "      <td>9.725223</td>\n",
       "      <td>0.00</td>\n",
       "      <td>25.00</td>\n",
       "      <td>3.076376</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 mean    min     max        std\n",
       "Dic         90.808558  62.50  100.00   5.239110\n",
       "Linguistic  72.499836  27.27   91.04   6.997561\n",
       "function    57.432591  18.18   81.82   6.368442\n",
       "Authentic   48.427896   1.00   99.00  31.763705\n",
       "Clout       45.867363   1.00   99.00  32.822569\n",
       "Analytic    28.277147   1.00   99.00  23.017036\n",
       "WPS         21.514736   4.75  290.00  20.345839\n",
       "Tone        21.153525   1.00   99.00  23.996762\n",
       "verb        19.156095   0.00   36.84   4.194490\n",
       "pronoun     18.356711   0.00   45.45   5.386416\n",
       "AllPunc     18.321898   0.00  101.59   7.788403\n",
       "Social      14.719523   0.00   42.22   5.811295\n",
       "BigWords    14.115044   0.00   50.00   5.026009\n",
       "ppron       13.671242   0.00   28.85   5.116679\n",
       "Cognition   13.460431   0.00   37.04   4.596143\n",
       "det         13.227912   0.00   36.36   3.493142\n",
       "prep        12.263474   0.00   29.41   3.147768\n",
       "cogproc     11.582760   0.00   29.23   4.305169\n",
       "socrefs     10.874130   0.00   33.33   5.016941\n",
       "auxverb      9.725223   0.00   25.00   3.076376"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# min max and std dev for each top var\n",
    "liwc_min = liwc[liwc_vars].min()\n",
    "liwc_max = liwc[liwc_vars].max()\n",
    "liwc_std = liwc[liwc_vars].std()\n",
    "\n",
    "liwc_avg = liwc_avg.to_frame()\n",
    "liwc_avg.columns = ['mean']\n",
    "liwc_avg['min'] = liwc_min\n",
    "liwc_avg['max'] = liwc_max\n",
    "liwc_avg['std'] = liwc_std\n",
    "\n",
    "liwc_avg = liwc_avg.sort_values(by='mean', ascending=False)\n",
    "liwc_avg.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "GPT4 - A (baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "liwc_gpt4A = pd.read_csv(\"../data/data_analysis/GPT4-A-LIWC-22 Results - directed_destigma_gpt_all - LIWC Analysis.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Dic</th>\n",
       "      <td>90.823441</td>\n",
       "      <td>62.50</td>\n",
       "      <td>100.00</td>\n",
       "      <td>5.236080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Linguistic</th>\n",
       "      <td>72.526212</td>\n",
       "      <td>27.27</td>\n",
       "      <td>91.04</td>\n",
       "      <td>6.999971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>function</th>\n",
       "      <td>57.449974</td>\n",
       "      <td>18.18</td>\n",
       "      <td>81.82</td>\n",
       "      <td>6.364886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Authentic</th>\n",
       "      <td>48.651521</td>\n",
       "      <td>1.00</td>\n",
       "      <td>99.00</td>\n",
       "      <td>31.851582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Clout</th>\n",
       "      <td>45.677483</td>\n",
       "      <td>1.00</td>\n",
       "      <td>99.00</td>\n",
       "      <td>32.880224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Analytic</th>\n",
       "      <td>28.252945</td>\n",
       "      <td>1.00</td>\n",
       "      <td>99.00</td>\n",
       "      <td>23.025722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WPS</th>\n",
       "      <td>21.491552</td>\n",
       "      <td>4.75</td>\n",
       "      <td>290.00</td>\n",
       "      <td>20.303846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tone</th>\n",
       "      <td>21.160291</td>\n",
       "      <td>1.00</td>\n",
       "      <td>99.00</td>\n",
       "      <td>23.997111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>verb</th>\n",
       "      <td>19.166381</td>\n",
       "      <td>0.00</td>\n",
       "      <td>36.84</td>\n",
       "      <td>4.194359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pronoun</th>\n",
       "      <td>18.357407</td>\n",
       "      <td>0.00</td>\n",
       "      <td>45.45</td>\n",
       "      <td>5.379906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AllPunc</th>\n",
       "      <td>18.310720</td>\n",
       "      <td>0.00</td>\n",
       "      <td>101.59</td>\n",
       "      <td>7.780965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Social</th>\n",
       "      <td>14.684227</td>\n",
       "      <td>0.00</td>\n",
       "      <td>42.22</td>\n",
       "      <td>5.825010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BigWords</th>\n",
       "      <td>14.109260</td>\n",
       "      <td>0.00</td>\n",
       "      <td>50.00</td>\n",
       "      <td>5.024932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ppron</th>\n",
       "      <td>13.670577</td>\n",
       "      <td>0.00</td>\n",
       "      <td>28.85</td>\n",
       "      <td>5.107988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cognition</th>\n",
       "      <td>13.464196</td>\n",
       "      <td>0.00</td>\n",
       "      <td>37.04</td>\n",
       "      <td>4.587518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>det</th>\n",
       "      <td>13.229551</td>\n",
       "      <td>0.00</td>\n",
       "      <td>36.36</td>\n",
       "      <td>3.486712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prep</th>\n",
       "      <td>12.265207</td>\n",
       "      <td>0.00</td>\n",
       "      <td>29.41</td>\n",
       "      <td>3.142710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cogproc</th>\n",
       "      <td>11.584630</td>\n",
       "      <td>0.00</td>\n",
       "      <td>29.23</td>\n",
       "      <td>4.297415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>socrefs</th>\n",
       "      <td>10.841327</td>\n",
       "      <td>0.00</td>\n",
       "      <td>33.33</td>\n",
       "      <td>5.031418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>auxverb</th>\n",
       "      <td>9.726554</td>\n",
       "      <td>0.00</td>\n",
       "      <td>25.00</td>\n",
       "      <td>3.074091</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 mean    min     max        std\n",
       "Dic         90.823441  62.50  100.00   5.236080\n",
       "Linguistic  72.526212  27.27   91.04   6.999971\n",
       "function    57.449974  18.18   81.82   6.364886\n",
       "Authentic   48.651521   1.00   99.00  31.851582\n",
       "Clout       45.677483   1.00   99.00  32.880224\n",
       "Analytic    28.252945   1.00   99.00  23.025722\n",
       "WPS         21.491552   4.75  290.00  20.303846\n",
       "Tone        21.160291   1.00   99.00  23.997111\n",
       "verb        19.166381   0.00   36.84   4.194359\n",
       "pronoun     18.357407   0.00   45.45   5.379906\n",
       "AllPunc     18.310720   0.00  101.59   7.780965\n",
       "Social      14.684227   0.00   42.22   5.825010\n",
       "BigWords    14.109260   0.00   50.00   5.024932\n",
       "ppron       13.670577   0.00   28.85   5.107988\n",
       "Cognition   13.464196   0.00   37.04   4.587518\n",
       "det         13.229551   0.00   36.36   3.486712\n",
       "prep        12.265207   0.00   29.41   3.142710\n",
       "cogproc     11.584630   0.00   29.23   4.297415\n",
       "socrefs     10.841327   0.00   33.33   5.031418\n",
       "auxverb      9.726554   0.00   25.00   3.074091"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#same\n",
    "liwc_vars = liwc_gpt4A.columns[26:]\n",
    "liwc_min_A = liwc_gpt4A[liwc_vars].min()\n",
    "liwc_max_A = liwc_gpt4A[liwc_vars].max()\n",
    "liwc_std_A = liwc_gpt4A[liwc_vars].std()\n",
    "liwc_avg_A = liwc_gpt4A[liwc_vars].mean()\n",
    "\n",
    "liwc_avg_A = liwc_avg_A.to_frame()\n",
    "liwc_avg_A.columns = ['mean']\n",
    "liwc_avg_A['min'] = liwc_min_A\n",
    "liwc_avg_A['max'] = liwc_max_A\n",
    "liwc_avg_A['std'] = liwc_std_A\n",
    "\n",
    "liwc_avg_A = liwc_avg_A.sort_values(by='mean', ascending=False)\n",
    "liwc_avg_A.head(20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### GPT4 - B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "liwc_gpt4B = pd.read_csv(\"../data/data_analysis/GPT4-B-LIWC-22 Results - directed_destigma_gpt_all - LIWC Analysis.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Dic</th>\n",
       "      <td>91.996942</td>\n",
       "      <td>66.67</td>\n",
       "      <td>100.00</td>\n",
       "      <td>4.680466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Linguistic</th>\n",
       "      <td>71.856408</td>\n",
       "      <td>22.22</td>\n",
       "      <td>93.17</td>\n",
       "      <td>7.436599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>function</th>\n",
       "      <td>56.642370</td>\n",
       "      <td>22.22</td>\n",
       "      <td>77.64</td>\n",
       "      <td>6.688771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Authentic</th>\n",
       "      <td>53.346680</td>\n",
       "      <td>1.00</td>\n",
       "      <td>99.00</td>\n",
       "      <td>32.886498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Clout</th>\n",
       "      <td>45.330908</td>\n",
       "      <td>1.00</td>\n",
       "      <td>99.00</td>\n",
       "      <td>32.508899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Analytic</th>\n",
       "      <td>33.606449</td>\n",
       "      <td>1.00</td>\n",
       "      <td>99.00</td>\n",
       "      <td>26.174268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tone</th>\n",
       "      <td>31.836788</td>\n",
       "      <td>1.00</td>\n",
       "      <td>99.00</td>\n",
       "      <td>30.321253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BigWords</th>\n",
       "      <td>22.424402</td>\n",
       "      <td>0.00</td>\n",
       "      <td>57.14</td>\n",
       "      <td>8.667040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>verb</th>\n",
       "      <td>18.739574</td>\n",
       "      <td>0.00</td>\n",
       "      <td>37.50</td>\n",
       "      <td>4.494888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pronoun</th>\n",
       "      <td>18.152381</td>\n",
       "      <td>0.00</td>\n",
       "      <td>42.86</td>\n",
       "      <td>6.037630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WPS</th>\n",
       "      <td>17.001991</td>\n",
       "      <td>4.40</td>\n",
       "      <td>183.00</td>\n",
       "      <td>9.272027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AllPunc</th>\n",
       "      <td>16.842047</td>\n",
       "      <td>0.00</td>\n",
       "      <td>101.72</td>\n",
       "      <td>6.187040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cognition</th>\n",
       "      <td>16.707496</td>\n",
       "      <td>0.00</td>\n",
       "      <td>50.00</td>\n",
       "      <td>5.657989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cogproc</th>\n",
       "      <td>15.485531</td>\n",
       "      <td>0.00</td>\n",
       "      <td>50.00</td>\n",
       "      <td>5.603948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Social</th>\n",
       "      <td>14.282494</td>\n",
       "      <td>0.00</td>\n",
       "      <td>39.13</td>\n",
       "      <td>5.981305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>det</th>\n",
       "      <td>13.280200</td>\n",
       "      <td>0.00</td>\n",
       "      <td>31.58</td>\n",
       "      <td>3.391954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prep</th>\n",
       "      <td>13.158456</td>\n",
       "      <td>0.00</td>\n",
       "      <td>31.58</td>\n",
       "      <td>2.971026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ppron</th>\n",
       "      <td>13.037311</td>\n",
       "      <td>0.00</td>\n",
       "      <td>32.00</td>\n",
       "      <td>6.083693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>socrefs</th>\n",
       "      <td>10.074649</td>\n",
       "      <td>0.00</td>\n",
       "      <td>39.13</td>\n",
       "      <td>5.196222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>auxverb</th>\n",
       "      <td>9.530559</td>\n",
       "      <td>0.00</td>\n",
       "      <td>25.00</td>\n",
       "      <td>3.127650</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 mean    min     max        std\n",
       "Dic         91.996942  66.67  100.00   4.680466\n",
       "Linguistic  71.856408  22.22   93.17   7.436599\n",
       "function    56.642370  22.22   77.64   6.688771\n",
       "Authentic   53.346680   1.00   99.00  32.886498\n",
       "Clout       45.330908   1.00   99.00  32.508899\n",
       "Analytic    33.606449   1.00   99.00  26.174268\n",
       "Tone        31.836788   1.00   99.00  30.321253\n",
       "BigWords    22.424402   0.00   57.14   8.667040\n",
       "verb        18.739574   0.00   37.50   4.494888\n",
       "pronoun     18.152381   0.00   42.86   6.037630\n",
       "WPS         17.001991   4.40  183.00   9.272027\n",
       "AllPunc     16.842047   0.00  101.72   6.187040\n",
       "Cognition   16.707496   0.00   50.00   5.657989\n",
       "cogproc     15.485531   0.00   50.00   5.603948\n",
       "Social      14.282494   0.00   39.13   5.981305\n",
       "det         13.280200   0.00   31.58   3.391954\n",
       "prep        13.158456   0.00   31.58   2.971026\n",
       "ppron       13.037311   0.00   32.00   6.083693\n",
       "socrefs     10.074649   0.00   39.13   5.196222\n",
       "auxverb      9.530559   0.00   25.00   3.127650"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# same\n",
    "liwc_vars = liwc_gpt4B.columns[29:]\n",
    "liwc_min_B = liwc_gpt4B[liwc_vars].min()\n",
    "liwc_max_B = liwc_gpt4B[liwc_vars].max()\n",
    "liwc_std_B = liwc_gpt4B[liwc_vars].std()\n",
    "\n",
    "# to frame\n",
    "liwc_avg_B = liwc_gpt4B[liwc_vars].mean()\n",
    "liwc_avg_B = liwc_avg_B.to_frame()\n",
    "liwc_avg_B.columns = ['mean']\n",
    "liwc_avg_B['min'] = liwc_min_B\n",
    "liwc_avg_B['max'] = liwc_max_B\n",
    "liwc_avg_B['std'] = liwc_std_B\n",
    "\n",
    "liwc_avg_B = liwc_avg_B.sort_values(by='mean', ascending=False)\n",
    "liwc_avg_B.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STRATEGY C\n",
    "\n",
    "liwc_gpt4C = pd.read_csv(\"../data/data_analysis/GPT4-C-LIWC-22 Results - directed_destigma_gpt_all - LIWC Analysis.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Dic</th>\n",
       "      <td>91.595069</td>\n",
       "      <td>0.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>7.818503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Linguistic</th>\n",
       "      <td>71.719800</td>\n",
       "      <td>0.00</td>\n",
       "      <td>92.68</td>\n",
       "      <td>8.947323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>function</th>\n",
       "      <td>56.685105</td>\n",
       "      <td>0.00</td>\n",
       "      <td>76.83</td>\n",
       "      <td>7.760931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Authentic</th>\n",
       "      <td>54.268389</td>\n",
       "      <td>1.00</td>\n",
       "      <td>99.00</td>\n",
       "      <td>32.937524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Clout</th>\n",
       "      <td>45.528066</td>\n",
       "      <td>1.00</td>\n",
       "      <td>99.00</td>\n",
       "      <td>32.934940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Analytic</th>\n",
       "      <td>32.358763</td>\n",
       "      <td>1.00</td>\n",
       "      <td>99.00</td>\n",
       "      <td>26.319953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tone</th>\n",
       "      <td>29.899800</td>\n",
       "      <td>1.00</td>\n",
       "      <td>99.00</td>\n",
       "      <td>29.570394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BigWords</th>\n",
       "      <td>22.152576</td>\n",
       "      <td>2.27</td>\n",
       "      <td>100.00</td>\n",
       "      <td>10.027904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>verb</th>\n",
       "      <td>18.681657</td>\n",
       "      <td>0.00</td>\n",
       "      <td>40.00</td>\n",
       "      <td>4.700482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pronoun</th>\n",
       "      <td>18.307204</td>\n",
       "      <td>0.00</td>\n",
       "      <td>41.09</td>\n",
       "      <td>6.132596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AllPunc</th>\n",
       "      <td>18.092196</td>\n",
       "      <td>0.00</td>\n",
       "      <td>95.16</td>\n",
       "      <td>6.322624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cognition</th>\n",
       "      <td>16.468692</td>\n",
       "      <td>0.00</td>\n",
       "      <td>46.15</td>\n",
       "      <td>5.618131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WPS</th>\n",
       "      <td>15.576229</td>\n",
       "      <td>1.00</td>\n",
       "      <td>286.00</td>\n",
       "      <td>7.936830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cogproc</th>\n",
       "      <td>15.183155</td>\n",
       "      <td>0.00</td>\n",
       "      <td>46.15</td>\n",
       "      <td>5.565373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Social</th>\n",
       "      <td>14.439123</td>\n",
       "      <td>0.00</td>\n",
       "      <td>35.64</td>\n",
       "      <td>6.172615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ppron</th>\n",
       "      <td>13.259271</td>\n",
       "      <td>0.00</td>\n",
       "      <td>34.48</td>\n",
       "      <td>6.093908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>det</th>\n",
       "      <td>13.253961</td>\n",
       "      <td>0.00</td>\n",
       "      <td>29.41</td>\n",
       "      <td>3.434290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prep</th>\n",
       "      <td>12.876090</td>\n",
       "      <td>0.00</td>\n",
       "      <td>31.25</td>\n",
       "      <td>3.172554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>socrefs</th>\n",
       "      <td>10.225931</td>\n",
       "      <td>0.00</td>\n",
       "      <td>31.40</td>\n",
       "      <td>5.300145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>auxverb</th>\n",
       "      <td>9.527968</td>\n",
       "      <td>0.00</td>\n",
       "      <td>20.37</td>\n",
       "      <td>3.191186</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 mean   min     max        std\n",
       "Dic         91.595069  0.00  100.00   7.818503\n",
       "Linguistic  71.719800  0.00   92.68   8.947323\n",
       "function    56.685105  0.00   76.83   7.760931\n",
       "Authentic   54.268389  1.00   99.00  32.937524\n",
       "Clout       45.528066  1.00   99.00  32.934940\n",
       "Analytic    32.358763  1.00   99.00  26.319953\n",
       "Tone        29.899800  1.00   99.00  29.570394\n",
       "BigWords    22.152576  2.27  100.00  10.027904\n",
       "verb        18.681657  0.00   40.00   4.700482\n",
       "pronoun     18.307204  0.00   41.09   6.132596\n",
       "AllPunc     18.092196  0.00   95.16   6.322624\n",
       "Cognition   16.468692  0.00   46.15   5.618131\n",
       "WPS         15.576229  1.00  286.00   7.936830\n",
       "cogproc     15.183155  0.00   46.15   5.565373\n",
       "Social      14.439123  0.00   35.64   6.172615\n",
       "ppron       13.259271  0.00   34.48   6.093908\n",
       "det         13.253961  0.00   29.41   3.434290\n",
       "prep        12.876090  0.00   31.25   3.172554\n",
       "socrefs     10.225931  0.00   31.40   5.300145\n",
       "auxverb      9.527968  0.00   20.37   3.191186"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "liwc_vars = liwc_gpt4C.columns[29:]\n",
    "liwc_min_C = liwc_gpt4C[liwc_vars].min()\n",
    "liwc_max_C = liwc_gpt4C[liwc_vars].max()\n",
    "liwc_std_C = liwc_gpt4C[liwc_vars].std()\n",
    "\n",
    "liwc_avg_C = liwc_gpt4C[liwc_vars].mean()\n",
    "liwc_avg_C = liwc_avg_C.to_frame()\n",
    "liwc_avg_C.columns = ['mean']\n",
    "liwc_avg_C['min'] = liwc_min_C\n",
    "liwc_avg_C['max'] = liwc_max_C\n",
    "liwc_avg_C['std'] = liwc_std_C\n",
    "\n",
    "liwc_avg_C = liwc_avg_C.sort_values(by='mean', ascending=False)\n",
    "liwc_avg_C.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "del liwc_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable</th>\n",
       "      <th>mean</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>std</th>\n",
       "      <th>mean_A</th>\n",
       "      <th>min_A</th>\n",
       "      <th>max_A</th>\n",
       "      <th>std_A</th>\n",
       "      <th>mean_B</th>\n",
       "      <th>min_B</th>\n",
       "      <th>max_B</th>\n",
       "      <th>std_B</th>\n",
       "      <th>mean_C</th>\n",
       "      <th>min_C</th>\n",
       "      <th>max_C</th>\n",
       "      <th>std_C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dic</td>\n",
       "      <td>90.808558</td>\n",
       "      <td>62.50</td>\n",
       "      <td>100.00</td>\n",
       "      <td>5.239110</td>\n",
       "      <td>90.823441</td>\n",
       "      <td>62.50</td>\n",
       "      <td>100.00</td>\n",
       "      <td>5.236080</td>\n",
       "      <td>91.996942</td>\n",
       "      <td>66.67</td>\n",
       "      <td>100.00</td>\n",
       "      <td>4.680466</td>\n",
       "      <td>91.595069</td>\n",
       "      <td>0.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>7.818503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Linguistic</td>\n",
       "      <td>72.499836</td>\n",
       "      <td>27.27</td>\n",
       "      <td>91.04</td>\n",
       "      <td>6.997561</td>\n",
       "      <td>72.526212</td>\n",
       "      <td>27.27</td>\n",
       "      <td>91.04</td>\n",
       "      <td>6.999971</td>\n",
       "      <td>71.856408</td>\n",
       "      <td>22.22</td>\n",
       "      <td>93.17</td>\n",
       "      <td>7.436599</td>\n",
       "      <td>71.719800</td>\n",
       "      <td>0.00</td>\n",
       "      <td>92.68</td>\n",
       "      <td>8.947323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>function</td>\n",
       "      <td>57.432591</td>\n",
       "      <td>18.18</td>\n",
       "      <td>81.82</td>\n",
       "      <td>6.368442</td>\n",
       "      <td>57.449974</td>\n",
       "      <td>18.18</td>\n",
       "      <td>81.82</td>\n",
       "      <td>6.364886</td>\n",
       "      <td>56.642370</td>\n",
       "      <td>22.22</td>\n",
       "      <td>77.64</td>\n",
       "      <td>6.688771</td>\n",
       "      <td>56.685105</td>\n",
       "      <td>0.00</td>\n",
       "      <td>76.83</td>\n",
       "      <td>7.760931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Authentic</td>\n",
       "      <td>48.427896</td>\n",
       "      <td>1.00</td>\n",
       "      <td>99.00</td>\n",
       "      <td>31.763705</td>\n",
       "      <td>48.651521</td>\n",
       "      <td>1.00</td>\n",
       "      <td>99.00</td>\n",
       "      <td>31.851582</td>\n",
       "      <td>53.346680</td>\n",
       "      <td>1.00</td>\n",
       "      <td>99.00</td>\n",
       "      <td>32.886498</td>\n",
       "      <td>54.268389</td>\n",
       "      <td>1.00</td>\n",
       "      <td>99.00</td>\n",
       "      <td>32.937524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Clout</td>\n",
       "      <td>45.867363</td>\n",
       "      <td>1.00</td>\n",
       "      <td>99.00</td>\n",
       "      <td>32.822569</td>\n",
       "      <td>45.677483</td>\n",
       "      <td>1.00</td>\n",
       "      <td>99.00</td>\n",
       "      <td>32.880224</td>\n",
       "      <td>45.330908</td>\n",
       "      <td>1.00</td>\n",
       "      <td>99.00</td>\n",
       "      <td>32.508899</td>\n",
       "      <td>45.528066</td>\n",
       "      <td>1.00</td>\n",
       "      <td>99.00</td>\n",
       "      <td>32.934940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Analytic</td>\n",
       "      <td>28.277147</td>\n",
       "      <td>1.00</td>\n",
       "      <td>99.00</td>\n",
       "      <td>23.017036</td>\n",
       "      <td>28.252945</td>\n",
       "      <td>1.00</td>\n",
       "      <td>99.00</td>\n",
       "      <td>23.025722</td>\n",
       "      <td>33.606449</td>\n",
       "      <td>1.00</td>\n",
       "      <td>99.00</td>\n",
       "      <td>26.174268</td>\n",
       "      <td>32.358763</td>\n",
       "      <td>1.00</td>\n",
       "      <td>99.00</td>\n",
       "      <td>26.319953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>WPS</td>\n",
       "      <td>21.514736</td>\n",
       "      <td>4.75</td>\n",
       "      <td>290.00</td>\n",
       "      <td>20.345839</td>\n",
       "      <td>21.491552</td>\n",
       "      <td>4.75</td>\n",
       "      <td>290.00</td>\n",
       "      <td>20.303846</td>\n",
       "      <td>17.001991</td>\n",
       "      <td>4.40</td>\n",
       "      <td>183.00</td>\n",
       "      <td>9.272027</td>\n",
       "      <td>15.576229</td>\n",
       "      <td>1.00</td>\n",
       "      <td>286.00</td>\n",
       "      <td>7.936830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Tone</td>\n",
       "      <td>21.153525</td>\n",
       "      <td>1.00</td>\n",
       "      <td>99.00</td>\n",
       "      <td>23.996762</td>\n",
       "      <td>21.160291</td>\n",
       "      <td>1.00</td>\n",
       "      <td>99.00</td>\n",
       "      <td>23.997111</td>\n",
       "      <td>31.836788</td>\n",
       "      <td>1.00</td>\n",
       "      <td>99.00</td>\n",
       "      <td>30.321253</td>\n",
       "      <td>29.899800</td>\n",
       "      <td>1.00</td>\n",
       "      <td>99.00</td>\n",
       "      <td>29.570394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>verb</td>\n",
       "      <td>19.156095</td>\n",
       "      <td>0.00</td>\n",
       "      <td>36.84</td>\n",
       "      <td>4.194490</td>\n",
       "      <td>19.166381</td>\n",
       "      <td>0.00</td>\n",
       "      <td>36.84</td>\n",
       "      <td>4.194359</td>\n",
       "      <td>18.739574</td>\n",
       "      <td>0.00</td>\n",
       "      <td>37.50</td>\n",
       "      <td>4.494888</td>\n",
       "      <td>18.681657</td>\n",
       "      <td>0.00</td>\n",
       "      <td>40.00</td>\n",
       "      <td>4.700482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>pronoun</td>\n",
       "      <td>18.356711</td>\n",
       "      <td>0.00</td>\n",
       "      <td>45.45</td>\n",
       "      <td>5.386416</td>\n",
       "      <td>18.357407</td>\n",
       "      <td>0.00</td>\n",
       "      <td>45.45</td>\n",
       "      <td>5.379906</td>\n",
       "      <td>18.152381</td>\n",
       "      <td>0.00</td>\n",
       "      <td>42.86</td>\n",
       "      <td>6.037630</td>\n",
       "      <td>18.307204</td>\n",
       "      <td>0.00</td>\n",
       "      <td>41.09</td>\n",
       "      <td>6.132596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>AllPunc</td>\n",
       "      <td>18.321898</td>\n",
       "      <td>0.00</td>\n",
       "      <td>101.59</td>\n",
       "      <td>7.788403</td>\n",
       "      <td>18.310720</td>\n",
       "      <td>0.00</td>\n",
       "      <td>101.59</td>\n",
       "      <td>7.780965</td>\n",
       "      <td>16.842047</td>\n",
       "      <td>0.00</td>\n",
       "      <td>101.72</td>\n",
       "      <td>6.187040</td>\n",
       "      <td>18.092196</td>\n",
       "      <td>0.00</td>\n",
       "      <td>95.16</td>\n",
       "      <td>6.322624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Social</td>\n",
       "      <td>14.719523</td>\n",
       "      <td>0.00</td>\n",
       "      <td>42.22</td>\n",
       "      <td>5.811295</td>\n",
       "      <td>14.684227</td>\n",
       "      <td>0.00</td>\n",
       "      <td>42.22</td>\n",
       "      <td>5.825010</td>\n",
       "      <td>14.282494</td>\n",
       "      <td>0.00</td>\n",
       "      <td>39.13</td>\n",
       "      <td>5.981305</td>\n",
       "      <td>14.439123</td>\n",
       "      <td>0.00</td>\n",
       "      <td>35.64</td>\n",
       "      <td>6.172615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>BigWords</td>\n",
       "      <td>14.115044</td>\n",
       "      <td>0.00</td>\n",
       "      <td>50.00</td>\n",
       "      <td>5.026009</td>\n",
       "      <td>14.109260</td>\n",
       "      <td>0.00</td>\n",
       "      <td>50.00</td>\n",
       "      <td>5.024932</td>\n",
       "      <td>22.424402</td>\n",
       "      <td>0.00</td>\n",
       "      <td>57.14</td>\n",
       "      <td>8.667040</td>\n",
       "      <td>22.152576</td>\n",
       "      <td>2.27</td>\n",
       "      <td>100.00</td>\n",
       "      <td>10.027904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ppron</td>\n",
       "      <td>13.671242</td>\n",
       "      <td>0.00</td>\n",
       "      <td>28.85</td>\n",
       "      <td>5.116679</td>\n",
       "      <td>13.670577</td>\n",
       "      <td>0.00</td>\n",
       "      <td>28.85</td>\n",
       "      <td>5.107988</td>\n",
       "      <td>13.037311</td>\n",
       "      <td>0.00</td>\n",
       "      <td>32.00</td>\n",
       "      <td>6.083693</td>\n",
       "      <td>13.259271</td>\n",
       "      <td>0.00</td>\n",
       "      <td>34.48</td>\n",
       "      <td>6.093908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Cognition</td>\n",
       "      <td>13.460431</td>\n",
       "      <td>0.00</td>\n",
       "      <td>37.04</td>\n",
       "      <td>4.596143</td>\n",
       "      <td>13.464196</td>\n",
       "      <td>0.00</td>\n",
       "      <td>37.04</td>\n",
       "      <td>4.587518</td>\n",
       "      <td>16.707496</td>\n",
       "      <td>0.00</td>\n",
       "      <td>50.00</td>\n",
       "      <td>5.657989</td>\n",
       "      <td>16.468692</td>\n",
       "      <td>0.00</td>\n",
       "      <td>46.15</td>\n",
       "      <td>5.618131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>det</td>\n",
       "      <td>13.227912</td>\n",
       "      <td>0.00</td>\n",
       "      <td>36.36</td>\n",
       "      <td>3.493142</td>\n",
       "      <td>13.229551</td>\n",
       "      <td>0.00</td>\n",
       "      <td>36.36</td>\n",
       "      <td>3.486712</td>\n",
       "      <td>13.280200</td>\n",
       "      <td>0.00</td>\n",
       "      <td>31.58</td>\n",
       "      <td>3.391954</td>\n",
       "      <td>13.253961</td>\n",
       "      <td>0.00</td>\n",
       "      <td>29.41</td>\n",
       "      <td>3.434290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>prep</td>\n",
       "      <td>12.263474</td>\n",
       "      <td>0.00</td>\n",
       "      <td>29.41</td>\n",
       "      <td>3.147768</td>\n",
       "      <td>12.265207</td>\n",
       "      <td>0.00</td>\n",
       "      <td>29.41</td>\n",
       "      <td>3.142710</td>\n",
       "      <td>13.158456</td>\n",
       "      <td>0.00</td>\n",
       "      <td>31.58</td>\n",
       "      <td>2.971026</td>\n",
       "      <td>12.876090</td>\n",
       "      <td>0.00</td>\n",
       "      <td>31.25</td>\n",
       "      <td>3.172554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>cogproc</td>\n",
       "      <td>11.582760</td>\n",
       "      <td>0.00</td>\n",
       "      <td>29.23</td>\n",
       "      <td>4.305169</td>\n",
       "      <td>11.584630</td>\n",
       "      <td>0.00</td>\n",
       "      <td>29.23</td>\n",
       "      <td>4.297415</td>\n",
       "      <td>15.485531</td>\n",
       "      <td>0.00</td>\n",
       "      <td>50.00</td>\n",
       "      <td>5.603948</td>\n",
       "      <td>15.183155</td>\n",
       "      <td>0.00</td>\n",
       "      <td>46.15</td>\n",
       "      <td>5.565373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>socrefs</td>\n",
       "      <td>10.874130</td>\n",
       "      <td>0.00</td>\n",
       "      <td>33.33</td>\n",
       "      <td>5.016941</td>\n",
       "      <td>10.841327</td>\n",
       "      <td>0.00</td>\n",
       "      <td>33.33</td>\n",
       "      <td>5.031418</td>\n",
       "      <td>10.074649</td>\n",
       "      <td>0.00</td>\n",
       "      <td>39.13</td>\n",
       "      <td>5.196222</td>\n",
       "      <td>10.225931</td>\n",
       "      <td>0.00</td>\n",
       "      <td>31.40</td>\n",
       "      <td>5.300145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>auxverb</td>\n",
       "      <td>9.725223</td>\n",
       "      <td>0.00</td>\n",
       "      <td>25.00</td>\n",
       "      <td>3.076376</td>\n",
       "      <td>9.726554</td>\n",
       "      <td>0.00</td>\n",
       "      <td>25.00</td>\n",
       "      <td>3.074091</td>\n",
       "      <td>9.530559</td>\n",
       "      <td>0.00</td>\n",
       "      <td>25.00</td>\n",
       "      <td>3.127650</td>\n",
       "      <td>9.527968</td>\n",
       "      <td>0.00</td>\n",
       "      <td>20.37</td>\n",
       "      <td>3.191186</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      variable       mean    min     max        std     mean_A  min_A   max_A  \\\n",
       "0          Dic  90.808558  62.50  100.00   5.239110  90.823441  62.50  100.00   \n",
       "1   Linguistic  72.499836  27.27   91.04   6.997561  72.526212  27.27   91.04   \n",
       "2     function  57.432591  18.18   81.82   6.368442  57.449974  18.18   81.82   \n",
       "3    Authentic  48.427896   1.00   99.00  31.763705  48.651521   1.00   99.00   \n",
       "4        Clout  45.867363   1.00   99.00  32.822569  45.677483   1.00   99.00   \n",
       "5     Analytic  28.277147   1.00   99.00  23.017036  28.252945   1.00   99.00   \n",
       "6          WPS  21.514736   4.75  290.00  20.345839  21.491552   4.75  290.00   \n",
       "7         Tone  21.153525   1.00   99.00  23.996762  21.160291   1.00   99.00   \n",
       "8         verb  19.156095   0.00   36.84   4.194490  19.166381   0.00   36.84   \n",
       "9      pronoun  18.356711   0.00   45.45   5.386416  18.357407   0.00   45.45   \n",
       "10     AllPunc  18.321898   0.00  101.59   7.788403  18.310720   0.00  101.59   \n",
       "11      Social  14.719523   0.00   42.22   5.811295  14.684227   0.00   42.22   \n",
       "12    BigWords  14.115044   0.00   50.00   5.026009  14.109260   0.00   50.00   \n",
       "13       ppron  13.671242   0.00   28.85   5.116679  13.670577   0.00   28.85   \n",
       "14   Cognition  13.460431   0.00   37.04   4.596143  13.464196   0.00   37.04   \n",
       "15         det  13.227912   0.00   36.36   3.493142  13.229551   0.00   36.36   \n",
       "16        prep  12.263474   0.00   29.41   3.147768  12.265207   0.00   29.41   \n",
       "17     cogproc  11.582760   0.00   29.23   4.305169  11.584630   0.00   29.23   \n",
       "18     socrefs  10.874130   0.00   33.33   5.016941  10.841327   0.00   33.33   \n",
       "19     auxverb   9.725223   0.00   25.00   3.076376   9.726554   0.00   25.00   \n",
       "\n",
       "        std_A     mean_B  min_B   max_B      std_B     mean_C  min_C   max_C  \\\n",
       "0    5.236080  91.996942  66.67  100.00   4.680466  91.595069   0.00  100.00   \n",
       "1    6.999971  71.856408  22.22   93.17   7.436599  71.719800   0.00   92.68   \n",
       "2    6.364886  56.642370  22.22   77.64   6.688771  56.685105   0.00   76.83   \n",
       "3   31.851582  53.346680   1.00   99.00  32.886498  54.268389   1.00   99.00   \n",
       "4   32.880224  45.330908   1.00   99.00  32.508899  45.528066   1.00   99.00   \n",
       "5   23.025722  33.606449   1.00   99.00  26.174268  32.358763   1.00   99.00   \n",
       "6   20.303846  17.001991   4.40  183.00   9.272027  15.576229   1.00  286.00   \n",
       "7   23.997111  31.836788   1.00   99.00  30.321253  29.899800   1.00   99.00   \n",
       "8    4.194359  18.739574   0.00   37.50   4.494888  18.681657   0.00   40.00   \n",
       "9    5.379906  18.152381   0.00   42.86   6.037630  18.307204   0.00   41.09   \n",
       "10   7.780965  16.842047   0.00  101.72   6.187040  18.092196   0.00   95.16   \n",
       "11   5.825010  14.282494   0.00   39.13   5.981305  14.439123   0.00   35.64   \n",
       "12   5.024932  22.424402   0.00   57.14   8.667040  22.152576   2.27  100.00   \n",
       "13   5.107988  13.037311   0.00   32.00   6.083693  13.259271   0.00   34.48   \n",
       "14   4.587518  16.707496   0.00   50.00   5.657989  16.468692   0.00   46.15   \n",
       "15   3.486712  13.280200   0.00   31.58   3.391954  13.253961   0.00   29.41   \n",
       "16   3.142710  13.158456   0.00   31.58   2.971026  12.876090   0.00   31.25   \n",
       "17   4.297415  15.485531   0.00   50.00   5.603948  15.183155   0.00   46.15   \n",
       "18   5.031418  10.074649   0.00   39.13   5.196222  10.225931   0.00   31.40   \n",
       "19   3.074091   9.530559   0.00   25.00   3.127650   9.527968   0.00   20.37   \n",
       "\n",
       "        std_C  \n",
       "0    7.818503  \n",
       "1    8.947323  \n",
       "2    7.760931  \n",
       "3   32.937524  \n",
       "4   32.934940  \n",
       "5   26.319953  \n",
       "6    7.936830  \n",
       "7   29.570394  \n",
       "8    4.700482  \n",
       "9    6.132596  \n",
       "10   6.322624  \n",
       "11   6.172615  \n",
       "12  10.027904  \n",
       "13   6.093908  \n",
       "14   5.618131  \n",
       "15   3.434290  \n",
       "16   3.172554  \n",
       "17   5.565373  \n",
       "18   5.300145  \n",
       "19   3.191186  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# join all three tables on variable name\n",
    "liwc_avg = liwc_avg.reset_index()\n",
    "liwc_avg_A = liwc_avg_A.reset_index()\n",
    "liwc_avg_B = liwc_avg_B.reset_index()\n",
    "liwc_avg_C = liwc_avg_C.reset_index()\n",
    "\n",
    "liwc_avg = liwc_avg.rename(columns={'index': 'variable'})\n",
    "liwc_avg_A = liwc_avg_A.rename(columns={'index': 'variable'})\n",
    "liwc_avg_B = liwc_avg_B.rename(columns={'index': 'variable'})\n",
    "liwc_avg_C = liwc_avg_C.rename(columns={'index': 'variable'})\n",
    "\n",
    "liwc_avg = liwc_avg.merge(liwc_avg_A, on='variable', suffixes=('', '_A'))\n",
    "liwc_avg = liwc_avg.merge(liwc_avg_B, on='variable', suffixes=('', '_B'))\n",
    "liwc_avg = liwc_avg.merge(liwc_avg_C, on='variable', suffixes=('', '_C'))\n",
    "\n",
    "liwc_avg = liwc_avg.sort_values(by='mean', ascending=False)\n",
    "liwc_avg.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "liwc_avg.to_csv(\"../data/data_analysis/liwc_compare.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## STAT ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import f_oneway\n",
    "\n",
    "# Get a list of all LIWC variables (assuming they start from the third column if the first two are 'variable' and 'mean')\n",
    "liwc_vars = liwc_avg.variable\n",
    "\n",
    "# make long table\n",
    "liwc_avg_long = pd.melt(liwc_avg, id_vars=['variable'], value_vars=['mean', 'mean_A', 'mean_B', 'mean_C'], var_name='strategy', value_name='value')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to hold p-values\n",
    "anova_results = {}\n",
    "\n",
    "for var in liwc_vars:\n",
    "    # Conduct ANOVA\n",
    "    f_val, p_val = f_oneway(liwc_avg['mean'], liwc_avg['mean_A'], liwc_avg['mean_B'], liwc_avg['mean_C'])\n",
    "    anova_results[var] = p_val\n",
    "\n",
    "# Print the results\n",
    "for var, p in anova_results.items():\n",
    "    if p < 0.05:\n",
    "        print(f\"{var}: p-value = {p}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try with pairwise t-test between mean and mean_C\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "# Dictionary to hold p-values\n",
    "ttest_results = {}\n",
    "\n",
    "for var in liwc_vars:\n",
    "    # Conduct t-test\n",
    "    t_val, p_val = ttest_ind(liwc_avg['mean'], liwc_avg['mean_C'])\n",
    "    ttest_results[var] = p_val\n",
    "\n",
    "# Print the results\n",
    "for var, p in ttest_results.items():\n",
    "    if p < 0.05:\n",
    "        print(f\"{var}: p-value = {p}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## WHO, WHAT, WHY?\n",
    "\n",
    "Using SRL to Understand the \"Why\":   \n",
    "*Identifying Key Verbs and Their Arguments:* SRL allows you to identify the verbs in each sentence and their corresponding arguments, which often include the agent (who), the act (what), and the purpose (why). By analyzing the predicates and their linked arguments, you can infer the intent or underlying motivation of the statement.\n",
    "\n",
    "*Analyzing Modal Verbs and Adverbs:* Look for modal verbs (e.g., must, should, could) and adverbs (e.g., necessarily, possibly, surely) that might indicate obligation, possibility, or certainty. These can provide clues about the speaker's attitudes or the degree of assertiveness, which might point to underlying reasons for the stigmatizing content.\n",
    "\n",
    "*Categorizing Intents Based on Predicates:* Group the posts based on the types of predicates used. For example, predicates expressing emotions (hate, love, fear) or cognitive processes (think, know, believe) can give insights into personal feelings or beliefs that drive the stigmatizing remarks.\n",
    "\n",
    "did stuff in colab: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyse colab results\n",
    "\n",
    "verb_subjects_by_topic = pd.read_csv(\"../data/data_analysis/verb_subjects_by_topic.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1     8342\n",
       " 0     2008\n",
       " 1     1814\n",
       " 3     1170\n",
       " 2     1122\n",
       " 4      464\n",
       " 6      307\n",
       " 7      241\n",
       " 8      215\n",
       " 9      153\n",
       " 13     125\n",
       " 12     103\n",
       " 10      98\n",
       " 14      57\n",
       " 5       46\n",
       " 15      42\n",
       " 11      19\n",
       " 17      13\n",
       " 18       8\n",
       " 16       7\n",
       "Name: topic, dtype: int64"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verb_subjects_by_topic['topic'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get top 2 verb-subject pairs for each topic\n",
    "# rename col\n",
    "verb_subjects_by_topic = verb_subjects_by_topic.rename(columns={'verb_subjects': 'count'})\n",
    "verb_subjects_by_topic = verb_subjects_by_topic.rename(columns={'Unnamed: 1': 'verb_subjects'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter []\n",
    "verb_subjects_by_topic = verb_subjects_by_topic[verb_subjects_by_topic['verb_subjects'] != '[]']\n",
    "verb_subjects_by_topic = verb_subjects_by_topic.groupby('topic').head(2)\n",
    "verb_subjects_by_topic.to_csv(\"../data/data_analysis/verb_subjects_by_topic.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>verb_subjects</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1</td>\n",
       "      <td>[('i', 'have')]</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1</td>\n",
       "      <td>[('i', 'want')]</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8343</th>\n",
       "      <td>0</td>\n",
       "      <td>[('i', 'have')]</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8344</th>\n",
       "      <td>0</td>\n",
       "      <td>[('i', 'hate')]</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10351</th>\n",
       "      <td>1</td>\n",
       "      <td>[('she', 'have')]</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10352</th>\n",
       "      <td>1</td>\n",
       "      <td>[('i', 'want')]</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12165</th>\n",
       "      <td>2</td>\n",
       "      <td>[('i', 'feel')]</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12166</th>\n",
       "      <td>2</td>\n",
       "      <td>[('i', 'do')]</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13287</th>\n",
       "      <td>3</td>\n",
       "      <td>[('i', 'hate')]</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13288</th>\n",
       "      <td>3</td>\n",
       "      <td>[('he', 'have')]</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14457</th>\n",
       "      <td>4</td>\n",
       "      <td>[('i', 'have')]</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14458</th>\n",
       "      <td>4</td>\n",
       "      <td>[('i', 'get')]</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14921</th>\n",
       "      <td>5</td>\n",
       "      <td>[('that', 's')]</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14922</th>\n",
       "      <td>5</td>\n",
       "      <td>[('that', '’')]</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14967</th>\n",
       "      <td>6</td>\n",
       "      <td>[('you', 'steal')]</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14968</th>\n",
       "      <td>6</td>\n",
       "      <td>[('he', 'steal')]</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15274</th>\n",
       "      <td>7</td>\n",
       "      <td>[('i', 'hate')]</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15275</th>\n",
       "      <td>7</td>\n",
       "      <td>[('it', 'make')]</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15515</th>\n",
       "      <td>8</td>\n",
       "      <td>[('it', 'hurt')]</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15516</th>\n",
       "      <td>8</td>\n",
       "      <td>[('we', 'have')]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15730</th>\n",
       "      <td>9</td>\n",
       "      <td>[('i', 'work')]</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15731</th>\n",
       "      <td>9</td>\n",
       "      <td>[('i', 'have')]</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15883</th>\n",
       "      <td>10</td>\n",
       "      <td>[('this', 'happen')]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15884</th>\n",
       "      <td>10</td>\n",
       "      <td>[('i', 'have')]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15981</th>\n",
       "      <td>11</td>\n",
       "      <td>[('you', 'come'), ('it', '’')]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15982</th>\n",
       "      <td>11</td>\n",
       "      <td>[('i', 'love')]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16000</th>\n",
       "      <td>12</td>\n",
       "      <td>[('i', 'laugh')]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16001</th>\n",
       "      <td>12</td>\n",
       "      <td>[('who', 'read')]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16103</th>\n",
       "      <td>13</td>\n",
       "      <td>[('i', 'have')]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16104</th>\n",
       "      <td>13</td>\n",
       "      <td>[('she', 'go')]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16228</th>\n",
       "      <td>14</td>\n",
       "      <td>[('ods', 'care'), ('fuck', 'care')]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16229</th>\n",
       "      <td>14</td>\n",
       "      <td>[('i', 'try'), ('i', 'get'), ('i', 'listen')]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16285</th>\n",
       "      <td>15</td>\n",
       "      <td>[('i', 'enjoy')]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16286</th>\n",
       "      <td>15</td>\n",
       "      <td>[('pal', 'send')]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16326</th>\n",
       "      <td>16</td>\n",
       "      <td>[('i', 'know')]</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16328</th>\n",
       "      <td>16</td>\n",
       "      <td>[('i', 'have')]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16334</th>\n",
       "      <td>17</td>\n",
       "      <td>[('i', 'have')]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16335</th>\n",
       "      <td>17</td>\n",
       "      <td>[('what', 'happen')]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16347</th>\n",
       "      <td>18</td>\n",
       "      <td>[('i', 'use')]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16348</th>\n",
       "      <td>18</td>\n",
       "      <td>[('account', 'vent')]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       topic                                  verb_subjects  count\n",
       "1         -1                                [('i', 'have')]    127\n",
       "2         -1                                [('i', 'want')]     80\n",
       "8343       0                                [('i', 'have')]     23\n",
       "8344       0                                [('i', 'hate')]     20\n",
       "10351      1                              [('she', 'have')]     29\n",
       "10352      1                                [('i', 'want')]     26\n",
       "12165      2                                [('i', 'feel')]     41\n",
       "12166      2                                  [('i', 'do')]     34\n",
       "13287      3                                [('i', 'hate')]     23\n",
       "13288      3                               [('he', 'have')]     18\n",
       "14457      4                                [('i', 'have')]      8\n",
       "14458      4                                 [('i', 'get')]      7\n",
       "14921      5                                [('that', 's')]      5\n",
       "14922      5                                [('that', '’')]      5\n",
       "14967      6                             [('you', 'steal')]      6\n",
       "14968      6                              [('he', 'steal')]      5\n",
       "15274      7                                [('i', 'hate')]     31\n",
       "15275      7                               [('it', 'make')]      4\n",
       "15515      8                               [('it', 'hurt')]      5\n",
       "15516      8                               [('we', 'have')]      3\n",
       "15730      9                                [('i', 'work')]      5\n",
       "15731      9                                [('i', 'have')]      5\n",
       "15883     10                           [('this', 'happen')]      3\n",
       "15884     10                                [('i', 'have')]      3\n",
       "15981     11                 [('you', 'come'), ('it', '’')]      1\n",
       "15982     11                                [('i', 'love')]      1\n",
       "16000     12                               [('i', 'laugh')]      3\n",
       "16001     12                              [('who', 'read')]      2\n",
       "16103     13                                [('i', 'have')]      2\n",
       "16104     13                                [('she', 'go')]      2\n",
       "16228     14            [('ods', 'care'), ('fuck', 'care')]      1\n",
       "16229     14  [('i', 'try'), ('i', 'get'), ('i', 'listen')]      1\n",
       "16285     15                               [('i', 'enjoy')]      2\n",
       "16286     15                              [('pal', 'send')]      1\n",
       "16326     16                                [('i', 'know')]      8\n",
       "16328     16                                [('i', 'have')]      1\n",
       "16334     17                                [('i', 'have')]      1\n",
       "16335     17                           [('what', 'happen')]      1\n",
       "16347     18                                 [('i', 'use')]      2\n",
       "16348     18                          [('account', 'vent')]      1"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verb_subjects_by_topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.-1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
