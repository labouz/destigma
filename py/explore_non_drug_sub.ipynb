{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "data = pickle.load(open('../data/non_drug_data_filtered.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keywords for lexical search from Eschliman et al. (2024)\n",
    "keywords = ['discrimination', 'discriminate', 'judge', 'judgment', 'judgement', 'different', \n",
    "            'not made for', 'label', 'labeling', 'labelling', 'stereotype', 'stereotyping', \n",
    "            'stereotypical', 'type', 'typed', 'status', 'shame', 'shamed', 'power', 'reputation',\n",
    "              'rep', 'rap', 'disregard', 'junkie', 'addict', 'criminal', 'hate', 'hater']\n",
    "# drugs = ['drug', 'drugs', 'substance', 'substances', 'addiction', 'addictive', 'addicted', 'dependency',\n",
    "#          'dependent', 'dependence', 'abuse', 'abuser', 'abusive', 'abusing', 'misuse', 'misuser', \n",
    "#          'misusing', 'misused', 'overdose', 'overdosing', 'overdosed', 'opioid', 'opiate', 'heroin', \n",
    "#          'kratom', 'crack', 'cocaine', 'meth', 'methamphetamine', 'methadone', 'fentanyl', 'buprenorphine',\n",
    "#          'suboxone', 'naloxone', 'naltrexone', 'weed', 'marijuana', 'cannabis', 'hash', 'hashish', \n",
    "#          'oxycontin', 'oxycodone', 'percocet', 'vicodin', 'hydrocodone', 'codeine', 'morphine', 'dilaudid',\n",
    "#          'xanax', 'valium', 'klonopin', 'ativan', 'benzo', 'benzodiazepine', 'alprazolam', 'diazepam',\n",
    "#          'LSD', 'acid', 'mushroom', 'psilocybin', 'MDMA', 'ecstasy', 'molly', 'ketamine', 'special K']\n",
    "\n",
    "drugs = ['drug', 'drugs', 'substance', 'substances', 'overdose', 'overdosing', 'overdosed', 'opioid', 'opiate', 'heroin', \n",
    "         'kratom', 'crack', 'cocaine', 'meth', 'methamphetamine', 'methadone', 'fentanyl', 'buprenorphine',\n",
    "         'suboxone', 'naloxone', 'naltrexone', 'weed', 'marijuana', 'cannabis', 'hash', 'hashish', \n",
    "         'oxycontin', 'oxycodone', 'percocet', 'vicodin', 'hydrocodone', 'codeine', 'morphine', 'dilaudid',\n",
    "         'xanax', 'valium', 'klonopin', 'ativan', 'benzo', 'benzodiazepine', 'alprazolam', 'diazepam',\n",
    "         'LSD', 'acid', 'mushroom', 'psilocybin', 'MDMA', 'ecstasy', 'molly', 'ketamine', 'special K']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle data\n",
    "data = data.sample(frac=1, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chatgpt code\n",
    "import re\n",
    "\n",
    "# Combine all keywords and drug names into two large regular expressions with word boundaries\n",
    "keywords_pattern = re.compile(r'\\b(?:discrimination|discriminate|judge|judgment|judgement|different|not made for|label|labeling|labelling|stereotype|stereotyping|stereotypical|type|typed|status|shame|shamed|power|reputation|rep|rap|disregard|junkie|addict|criminal|hate|hater)\\b', re.IGNORECASE)\n",
    "drugs_pattern = re.compile(r'\\b(?:drug|drugs|substance|substances|overdose|overdosing|overdosed|opioid|opiate|heroin|kratom|crack|cocaine|meth|methamphetamine|methadone|fentanyl|buprenorphine|suboxone|naloxone|naltrexone|weed|marijuana|cannabis|hash|hashish|oxycontin|oxycodone|percocet|vicodin|hydrocodone|codeine|morphine|dilaudid|xanax|valium|klonopin|ativan|benzo|benzodiazepine|alprazolam|diazepam|LSD|acid|mushroom|psilocybin|MDMA|ecstasy|molly|ketamine|special K)\\b', re.IGNORECASE)\n",
    "\n",
    "sample_posts = []\n",
    "while len(sample_posts) < 1000:\n",
    "    for i, row in data.iterrows():\n",
    "        if re.search(drugs_pattern, row['text']) and re.search(keywords_pattern, row['text']):\n",
    "            sample_posts.append(row['text'])\n",
    "        if len(sample_posts) == 1000:\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I hope my junkie sister OD's or disappears out of our lives My sister is an alcoholic junkie who has 2 DUIs under her belt as well as loves taking Xanax and alcohol together and wreaking havoc for our family and even strangers.\n",
      "\n",
      "This started like 8 years ago and at first I wanted her to get better, but now that I thought back on our lives and realized she's been a piece of garbage even when she was a child. She would bully her childhood friends so once everyone grew up and got wiser they shunned and abandoned her.  Pretty sure she got the shit kicked out of her too.\n",
      "\n",
      "She's tried to falsely accuse various people of raping her including my dad who has spent almost the past 10 years keeping her out of shit and covering for her with the law and having to go looking for her in the middle of the night to make sure she wasn't dead in a gutter somewhere.\n",
      "\n",
      "I don't give a shit if she is alive or dead or just disappears never to be heard from again.  I have given up on her and now all I see is a alcoholic junkie who thinks she has no problems and is better then everyone else.\n"
     ]
    }
   ],
   "source": [
    "print(sample_posts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export to csv\n",
    "df = pd.DataFrame(sample_posts, columns=['text'])\n",
    "df.to_csv('../data/sample_nondrug_posts.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys_prompt = f\"\"\"\n",
    "You are an expert social scientist who has been asked to analyze a dataset of 1000 social media posts.\n",
    "In this dataset, you are looking for posts that contain stigmatizing language about drug use.\n",
    "Stigmatizing language includes terms that are judgmental, discriminatory, or stereotypical and can contribute to negative perceptions of individuals who use drugs.\n",
    "For example, terms like \"junkie,\" \"addict,\" or \"criminal\" are considered stigmatizing.\n",
    "If the post contains stigmatizing language about drug use, you should flag it for further review by labeling it as \"stigmatizing.\" \n",
    "If the post does not contain stigmatizing language about drug use, you should label it as \"non-stigmatizing.\"\n",
    "If the post is not related to drug use at all, you should label it as \"not drug-related.\"\n",
    "Respond with only one of the following labels: \"stigmatizing,\" \"non-stigmatizing,\" or \"not drug-related.\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import time\n",
    "\n",
    "api_key = \"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\"\n",
    "client = OpenAI(api_key = api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_is_stigma(sentence, sys_prompt, retries=2, model=\"gpt-3.5-turbo-0125\"):\n",
    "    example1 = \"I hope my junkie sister OD's or disappears out of our lives.\"    \n",
    "    answer1 = \"stigma\"\n",
    "    example2 = \"She asked me how many times I've done it and I said 2 even though it was a lie.  She just looked at me with utter disappointment and almost started crying.  What do I do? \"\n",
    "    answer2 = \"no stigma\"\n",
    "    while retries > 0:\n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": sys_prompt,\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": example1,\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"assistant\",\n",
    "                    \"content\": answer1,\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": example2,\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"assistant\",\n",
    "                    \"content\": answer2,\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": sentence,\n",
    "                }\n",
    "            ],\n",
    "            model=model,\n",
    "            temperature=0\n",
    "        )\n",
    "            label = response.choices[0].message.content.lower().strip()\n",
    "            return label\n",
    "        except Exception as e:\n",
    "            if e:\n",
    "                print(e)\n",
    "                retries -= 1\n",
    "                time.sleep(5)\n",
    "            else:\n",
    "                raise e\n",
    "    print(\"Retrying...\")\n",
    "    return \"skipped\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"gpt_3_5_2\"] = df[\"text\"].apply(lambda x: label_is_stigma(x, sys_prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel('../data/is_stigma/sample_nondrug_posts_gpt_3_5.xlsx', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
